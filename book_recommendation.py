# -*- coding: utf-8 -*-
"""Collaborative and Content Based Combined.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P8OQ9fPvzqNchsCDr2sWG5lnllWUpR_8
"""

import pandas as pd
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
import numpy as np
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import correlation
from sklearn.metrics.pairwise import pairwise_distances
import ipywidgets as widgets
from IPython.display import display, clear_output
from contextlib import contextmanager
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import os, sys
import re
import seaborn as sns

from IPython.display import HTML

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from sklearn.metrics.pairwise import linear_kernel
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import RegexpTokenizer
import re
import string
import random
from PIL import Image
import requests
from io import BytesIO
import matplotlib.pyplot as plt
# %matplotlib inline

#copied_path = 'drive/MyDrive/datasets/BX-Books.csv' #remove ‘content/’ from path then use 
#data = pd.read_csv(copied_path)
books = pd.read_csv("BX-Books.csv", sep=';', on_bad_lines = "skip", encoding="latin-1")
books.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']


#copied_path = 'drive/MyDrive/datasets/BX-Users.csv' #remove ‘content/’ from path then use 
users = pd.read_csv("BX-Users.csv", sep=';', on_bad_lines = "skip", encoding="latin-1")
users.columns = ['userID', 'Location', 'Age']

#copied_path = 'drive/MyDrive/datasets/BX-Book-Ratings.csv' #remove ‘content/’ from path then use
ratings = pd.read_csv("BX-Book-Ratings.csv", sep=';', on_bad_lines = "skip", encoding="latin-1")
ratings.columns = ['userID', 'ISBN', 'bookRating']


#dropping last three columns containing image URLs which will not be required for analysis
#books.drop(['imageUrlS', 'imageUrlM', 'imageUrlL'],axis=1,inplace=True)

#making this setting to display full text in columns
pd.set_option('display.max_colwidth', +1)

#making required corrections as above, keeping other fields intact
books.loc[books.ISBN == '2070426769','yearOfPublication'] = 2003
books.loc[books.ISBN == '2070426769','bookAuthor'] = "Jean-Marie Gustave Le ClÃ?Â©zio"
books.loc[books.ISBN == '2070426769','publisher'] = "Gallimard"
books.loc[books.ISBN == '2070426769','bookTitle'] = "Peuple du ciel, suivi de 'Les Bergers"

#Correcting the dtypes of yearOfPublication
books.yearOfPublication=pd.to_numeric(books.yearOfPublication, errors='coerce')

#However, the value 0 is invalid and as this dataset was published in 2004, I have assumed the the years after 2006 to be 
#invalid keeping some margin in case dataset was updated thereafer
#setting invalid years as NaN
books.loc[(books.yearOfPublication > 2006) | (books.yearOfPublication == 0),'yearOfPublication'] = np.NAN

#replacing NaNs with mean value of yearOfPublication
books.yearOfPublication.fillna(round(books.yearOfPublication.mean()), inplace=True)

#resetting the dtype as int32
books.yearOfPublication = books.yearOfPublication.astype(np.int32)

#since there is nothing in common to infer publisher for NaNs, replacing these with 'other
books.loc[(books.ISBN == '193169656X'),'publisher'] = 'other'
books.loc[(books.ISBN == '1931696993'),'publisher'] = 'other'

#In my view values below 5 and above 90 do not make much sense for our book rating case...hence replacing these by NaNs
users.loc[(users.Age > 90) | (users.Age < 5), 'Age'] = np.nan

#replacing NaNs with mean
users.Age = users.Age.fillna(users.Age.mean())

#setting the data type as int
users.Age = users.Age.astype(np.int32)

#ratings dataset should have books only which exist in our books dataset, unless new books are added to books dataset
ratings_new = ratings[ratings.ISBN.isin(books.ISBN)]

#ratings dataset should have ratings from users which exist in users dataset, unless new users are added to users dataset
ratings = ratings[ratings.userID.isin(users.userID)]

#ratings dataset will have n_users*n_books entries if every user rated every item, this shows that the dataset is very sparse
n_users = users.shape[0]
n_books = books.shape[0]
#Sparsity of dataset in %
sparsity=1.0-len(ratings_new)/float(n_users*n_books)

#Hence segragating implicit and explict ratings datasets
ratings_explicit = ratings_new[ratings_new.bookRating != 0]
ratings_implicit = ratings_new[ratings_new.bookRating == 0]


from sklearn.metrics.pairwise import cosine_similarity

"""**Simple Rating Based Recommendation System**"""

#At this point , a simple popularity based recommendation system can be built based on count of user ratings for different books
# def RatingBasedRecommendation():
#     ratings_count = pd.DataFrame(ratings_explicit.groupby(['ISBN'])['bookRating'].sum())
#     #ratings_count_avg = pd.DataFrame(ratings_explicit.groupby(['ISBN'])['bookRating'].mean())
#     top10 = ratings_count.sort_values('bookRating', ascending = False).head(10)
#     Top10=top10.merge(books, left_index = True, right_on = 'ISBN')
#     data=[]
#     for i in range(10):
#         res={}
#         res["name"]=books.bookTitle[Top10.index[i]]
#         res["url"]=books.imageUrlM[Top10.index[i]]
#         res["author"]=books.bookAuthor[Top10.index[i]]
#         res["year"]=books.yearOfPublication[Top10.index[i]]
#         res["publisher"]=books.publisher[Top10.index[i]]
#         data.append(res)
#     #i=books.imageUrlL[Top10.index[i]]
#     #response = requests.get(i)
#     #img = Image.open(BytesIO(response.content))
#     #plt.figure()
#     #plt.imshow(img)
#     return data 

#RatingBasedRecommendation() 
#Similarly segregating users who have given explicit ratings from 1-10 and those whose implicit behavior was tracked
users_exp_ratings = users[users.userID.isin(ratings_explicit.userID)]
users_imp_ratings = users[users.userID.isin(ratings_implicit.userID)]

#checking shapes
# print(users.shape)
# print(users_exp_ratings.shape)
# print(users_imp_ratings.shape)

"""**Collaborative Filtering Based Recommendation Systems**"""

#To cope up with computing power I have and to reduce the dataset size, I am considering users who have rated atleast 100 books
#and books which have atleast 100 ratings
counts1 = ratings_explicit['userID'].value_counts()
ratings_explicit = ratings_explicit[ratings_explicit['userID'].isin(counts1[counts1 >= 100].index)]
counts = ratings_explicit['bookRating'].value_counts()
ratings_explicit = ratings_explicit[ratings_explicit['bookRating'].isin(counts[counts >= 100].index)]

#Generating ratings matrix from explicit ratings table
ratings_matrix = ratings_explicit.pivot(index='userID', columns='ISBN', values='bookRating')
userID = ratings_matrix.index
ISBN = ratings_matrix.columns
#print(ratings_matrix.shape)
ratings_matrix.head()
#Notice that most of the values are NaN (undefined) implying absence of ratings

n_users = ratings_matrix.shape[0] #considering only those users who gave explicit ratings
n_books = ratings_matrix.shape[1]
#print(n_users, n_books)

#since NaNs cannot be handled by training algorithms, replacing these by 0, which indicates absence of ratings
#setting data type
ratings_matrix.fillna(0, inplace = True)
ratings_matrix = ratings_matrix.astype(np.int32)

#checking first few rows
ratings_matrix.head(5)

#rechecking the sparsity
sparsity=1.0-len(ratings_explicit)/float(users_exp_ratings.shape[0]*n_books)
#print('The sparsity level of Book Crossing dataset is ' +  str(sparsity*100) + ' %')

"""**Training our recommendation system**"""

#setting global variables
global metric,k
k=10
metric='cosine'

"""**User-based Recommendation System**"""

#This function finds k similar users given the user_id and ratings matrix 
#These similarities are same as obtained via using pairwise_distances
def findksimilarusers(user_id, ratings, metric = metric, k=k):
    similarities=[]
    indices=[]
    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute') 
    model_knn.fit(ratings)
    loc = ratings.index.get_loc(user_id)
    distances, indices = model_knn.kneighbors(ratings.iloc[loc, :].values.reshape(1, -1), n_neighbors = k+1)
    similarities = 1-distances.flatten()
            
    return similarities,indices

#This function predicts rating for specified user-item combination based on user-based approach
def predict_userbased(user_id, item_id, ratings, metric = metric, k=k):
    prediction=0
    user_loc = ratings.index.get_loc(user_id)
    item_loc = ratings.columns.get_loc(item_id)
    similarities, indices=findksimilarusers(user_id, ratings,metric, k) #similar users based on cosine similarity
    mean_rating = ratings.iloc[user_loc,:].mean() #to adjust for zero based indexing
    sum_wt = np.sum(similarities)-1
    product=1
    wtd_sum = 0 
    
    for i in range(0, len(indices.flatten())):
        if indices.flatten()[i] == user_loc:
            continue;
        else: 
            ratings_diff = ratings.iloc[indices.flatten()[i],item_loc]-np.mean(ratings.iloc[indices.flatten()[i],:])
            product = ratings_diff * (similarities[i])
            wtd_sum = wtd_sum + product
    
    #in case of very sparse datasets, using correlation metric for collaborative based approach may give negative ratings
    #which are handled here as below
    if prediction <= 0:
        prediction = 1   
    elif prediction >10:
        prediction = 10
    
    prediction = int(round(mean_rating + (wtd_sum/sum_wt)))
    #print('\nPredicted rating for user {0} -> item {1}: {2}'.format(user_id,item_id,prediction))

    return prediction

predict_userbased(11676,'0001056107',ratings_matrix);

"""
**Item-based Recommendation Systems**"""

#This function finds k similar items given the item_id and ratings matrix

def findksimilaritems(item_id, ratings, metric=metric, k=k):
    similarities=[]
    indices=[]
    ratings=ratings.T
    loc = ratings.index.get_loc(item_id)
    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute')
    model_knn.fit(ratings)
    
    distances, indices = model_knn.kneighbors(ratings.iloc[loc, :].values.reshape(1, -1), n_neighbors = k+1)
    similarities = 1-distances.flatten()

    return similarities,indices

similarities,indices=findksimilaritems('0001056107',ratings_matrix)

#This function predicts the rating for specified user-item combination based on item-based approach
def predict_itembased(user_id, item_id, ratings, metric = metric, k=k):
    prediction= wtd_sum =0
    user_loc = ratings.index.get_loc(user_id)
    item_loc = ratings.columns.get_loc(item_id)
    similarities, indices=findksimilaritems(item_id, ratings) #similar users based on correlation coefficients
    sum_wt = np.sum(similarities)-1
    product=1
    for i in range(0, len(indices.flatten())):
        if indices.flatten()[i] == item_loc:
            continue;
        else:
            product = ratings.iloc[user_loc,indices.flatten()[i]] * (similarities[i])
            wtd_sum = wtd_sum + product                              
    prediction = int(round(wtd_sum/sum_wt))
    
    #in case of very sparse datasets, using correlation metric for collaborative based approach may give negative ratings
    #which are handled here as below //code has been validated without the code snippet below, below snippet is to avoid negative
    #predictions which might arise in case of very sparse datasets when using correlation metric
    if prediction <= 0:
        prediction = 1   
    elif prediction >10:
        prediction = 10

    #print('\nPredicted rating for user {0} -> item {1}: {2}'.format(user_id,item_id,prediction))      
    
    return prediction

prediction = predict_itembased(11676,'0001056107',ratings_matrix)

#This function utilizes above functions to recommend items for item/user based approach and cosine/correlation. 
#Recommendations are made if the predicted rating for an item is >= to 6,and the items have not been rated already
def ItemBasedCFCorrelation(user_id, ratings, metric=metric):    
    if (user_id not in ratings.index.values) or type(user_id) is not int:
        print("User id should be a valid integer from this list :\n\n {} ".format(re.sub('[\[\]]', '', np.array_str(ratings_matrix.index.values))))
    else:    
        prediction = []                   
        metric = 'correlation'
        #item based
        for i in range(ratings.shape[1]):
            if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already
                prediction.append(predict_itembased(user_id, str(ratings.columns[i]) ,ratings, metric))
            else:                    
                prediction.append(-1) #for already rated items
        prediction = pd.Series(prediction)
        prediction = prediction.sort_values(ascending=False)
        recommended = prediction[:10]
        data=[]
        #print("Recommendation of books based on -Based Collaborative filtering using correlation as similarity measure is:")
        for i in range(len(recommended)):
            #print("{0}. {1}".format(i+1,books.bookTitle[recommended.index[i]].encode('utf-8')))
        #for i in range(10):
            res={}
            res["name"]=books.bookTitle[recommended.index[i]]
            res["url"]=books.imageUrlM[recommended.index[i]]
            res["author"]=books.bookAuthor[recommended.index[i]]
            res["year"]=books.yearOfPublication[recommended.index[i]]
            res["publisher"]=books.publisher[recommended.index[i]]
            print(res)
            data.append(res)
        #i=books.imageUrlL[Top10.index[i]]
        #response = requests.get(i)
        #img = Image.open(BytesIO(response.content))
        #plt.figure()
        #plt.imshow(img)
        return data 
#This function utilizes above functions to recommend items for item/user based approach and cosine/correlation. 
#Recommendations are made if the predicted rating for an item is >= to 6,and the items have not been rated already
def ItemBasedCFCosine(user_id, ratings, metric=metric):    
    # if (user_id not in ratings.index.values) or type(user_id) is not int:
    #     print("User id should be a valid integer from this list :\n\n {} ".format(re.sub('[\[\]]', '', np.array_str(ratings_matrix.index.values))))
    # else:    
    prediction = []                   
    metric = 'cosine'
        #item based
    for i in range(ratings.shape[1]):
        if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already
            prediction.append(predict_itembased(user_id, str(ratings.columns[i]) ,ratings, metric))
        else:                    
            prediction.append(-1) #for already rated items
    prediction = pd.Series(prediction)
    prediction = prediction.sort_values(ascending=False)
    recommended = prediction[:10]
    data=[]
        #print("Recommendation of books based on -Based Collaborative filtering using correlation as similarity measure is:")
    for i in range(len(recommended)):
            #print("{0}. {1}".format(i+1,books.bookTitle[recommended.index[i]].encode('utf-8')))
        #for i in range(10):
        res={}
        res["ISBN"]=books.ISBN[recommended.index[i]]
        res["name"]=books.bookTitle[recommended.index[i]]
        res["url"]=books.imageUrlM[recommended.index[i]]
        res["author"]=books.bookAuthor[recommended.index[i]]
        res["year"]=books.yearOfPublication[recommended.index[i]]
        res["publisher"]=books.publisher[recommended.index[i]]
        print(res)
        data.append(res)
        #i=books.imageUrlL[Top10.index[i]]
        #response = requests.get(i)
        #img = Image.open(BytesIO(response.content))
        #plt.figure()
        #plt.imshow(img)
    return data 

#This function utilizes above functions to recommend items for item/user based approach and cosine/correlation. 
#Recommendations are made if the predicted rating for an item is >= to 6,and the items have not been rated already
def UserBasedCFCorrelation(user_id, ratings, metric=metric):    
    if (user_id not in ratings_matrix.index.values) or type(user_id) is not int:
        print("User id should be a valid integer from this list :\n\n {} ".format(re.sub('[\[\]]', '', np.array_str(ratings_matrix.index.values))))
    else:    
        prediction = []                   
        metric = 'correlation'
        #item based
        for i in range(ratings.shape[1]):
            if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already
                prediction.append(predict_userbased(user_id, str(ratings.columns[i]) ,ratings, metric))
            else:                    
                prediction.append(-1) #for already rated items
        prediction = pd.Series(prediction)
        prediction = prediction.sort_values(ascending=False)
        recommended = prediction[:10]
        data=[]
        #print("Recommendation of books based on -Based Collaborative filtering using correlation as similarity measure is:")
        for i in range(len(recommended)):
            #print("{0}. {1}".format(i+1,books.bookTitle[recommended.index[i]].encode('utf-8')))
        #for i in range(10):
            res={}
            res["name"]=books.bookTitle[recommended.index[i]]
            res["url"]=books.imageUrlM[recommended.index[i]]
            res["author"]=books.bookAuthor[recommended.index[i]]
            res["year"]=books.yearOfPublication[recommended.index[i]]
            res["publisher"]=books.publisher[recommended.index[i]]
            print(res)
            data.append(res)
        #i=books.imageUrlL[Top10.index[i]]
        #response = requests.get(i)
        #img = Image.open(BytesIO(response.content))
        #plt.figure()
        #plt.imshow(img)
        return data 

#This function utilizes above functions to recommend items for item/user based approach and cosine/correlation. 
#Recommendations are made if the predicted rating for an item is >= to 6,and the items have not been rated already
def UserBasedCFCosine(user_id, ratings, metric=metric):    
    # if (user_id not in ratings_matrix.index.values) or type(user_id) is not int:
    #     print("User id should be a valid integer from this list :\n\n {} ".format(re.sub('[\[\]]', '', np.array_str(ratings_matrix.index.values))))
    # else:    
    prediction = []                   
    metric = 'cosine'
        #item based
    for i in range(ratings.shape[1]):
        if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already
            prediction.append(predict_userbased(user_id, str(ratings.columns[i]) ,ratings, metric))
        else:                    
            prediction.append(-1) #for already rated items
    prediction = pd.Series(prediction)
    prediction = prediction.sort_values(ascending=False)
    recommended = prediction[:10]
    data=[]
        #print("Recommendation of books based on -Based Collaborative filtering using correlation as similarity measure is:")
    for i in range(len(recommended)):
            #print("{0}. {1}".format(i+1,books.bookTitle[recommended.index[i]].encode('utf-8')))
        #for i in range(10):
        res={}
        res["ISBN"]=books.ISBN[recommended.index[i]]
        res["name"]=books.bookTitle[recommended.index[i]]
        res["url"]=books.imageUrlM[recommended.index[i]]
        res["author"]=books.bookAuthor[recommended.index[i]]
        res["year"]=books.yearOfPublication[recommended.index[i]]
        res["publisher"]=books.publisher[recommended.index[i]]
        #print(res)
        data.append(res)
        #i=books.imageUrlL[Top10.index[i]]
        #response = requests.get(i)
        #img = Image.open(BytesIO(response.content))
        #plt.figure()
        #plt.imshow(img)
    return data 
        

#ItemBasedCFCorrelation(int(input("Enter Id")), ratings_matrix)

#ItemBasedCFCosine(int(input("Enter Id")), ratings_matrix)

#UserBasedCFCorrelation(int(input("Enter Id")), ratings_matrix)
# print(list(ratings_matrix.index.values))
#UserBasedCFCosine(int(input("Enter Id")), ratings_matrix)

# #trial method not to run
# #will work here after content based filtering
# #has some logical error 

# #This function utilizes above functions to recommend items for item/user based approach and cosine/correlation. 
# #Recommendations are made if the predicted rating for an item is >= to 6,and the items have not been rated already
# def recommendItem(user_id, ratings, metric=metric):    
#     if (user_id not in ratings.index.values) or type(user_id) is not int:
#         print("User id should be a valid integer from this list :\n\n {} ".format(re.sub('[\[\]]', '', np.array_str(ratings_matrix.index.values))))
#     else:    
#         ids = ['Item-based (correlation)','Item-based (cosine)','User-based (correlation)','User-based (cosine)']
#         select = widgets.Dropdown(options=ids, value=ids[0],description='Select approach', width='1000px')
#         def on_change(change):
#             clear_output(wait=True)
#             prediction = []            
#             if change['type'] == 'change' and change['name'] == 'value':            
#                 if (select.value == 'Item-based (correlation)') | (select.value == 'User-based (correlation)') :
#                     metric = 'correlation'
#                 else:                       
#                     metric = 'cosine'   
#                 with suppress_stdout():
#                     if (select.value == 'Item-based (correlation)') | (select.value == 'Item-based (cosine)'):
#                         for i in range(ratings.shape[1]):
#                             if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already
#                                 prediction.append(predict_itembased(user_id, str(ratings.columns[i]) ,ratings, metric))
#                             else:                    
#                                 prediction.append(-1) #for already rated items
#                     else:
#                         for i in range(ratings.shape[1]):
#                             if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already
#                                 prediction.append(predict_userbased(user_id, str(ratings.columns[i]) ,ratings, metric))
#                             else:                    
#                                 prediction.append(-1) #for already rated items
#                 prediction = pd.Series(prediction)
#                 prediction = prediction.sort_values(ascending=False)
#                 recommended = prediction[:10]
#                 print("As per {0} approach....Following books are recommended...".format(select.value))
#                 for i in range(len(recommended)):
#                      print("{0}. {1}".format(i+1,books.bookTitle[recommended.index[i]].encode('utf-8')))                        
#         select.observe(on_change)
#         display(select)

# ratings.head()

# ratings_matrix.head()

# ratings.index.values

# ratings['userID']

# UserBasedCFCosine(int(input()), ratings_matrix)
userids=list(ratings_matrix.index.values)
#print(userids)
#print(len(userids))

def getuserid(id):
    #print((id)%(len(userids)))
    return(userids[(id)%(len(userids))])
def getrandombooks():
    df=books.sample(1)
    df.reset_index(level = 0, inplace = True)
    res={}
    res["ISBN"]=df['ISBN'][0]
    res["name"]=df['bookTitle'][0]
    #print(df['bookTitle'][0])
    res["url"]=df['imageUrlL'][0]
    res["author"]=df['bookAuthor'][0]
    res["year"]=df['yearOfPublication'][0]
    res["publisher"]=df['publisher'][0]
    #print(res)
        #i=books.imageUrlL[Top10.index[i]]
        #response = requests.get(i)
        #img = Image.open(BytesIO(response.content))
        #plt.figure()
        #plt.imshow(img)
    return res 
def searchandrate(isbn):
    isbn=str(isbn)
    df=books.loc[books['ISBN'] == isbn]
    df.reset_index(level = 0, inplace = True)
    res={}
    res["ISBN"]=df['ISBN'][0]
    res["name"]=df['bookTitle'][0]
    #print(df['bookTitle'][0])
    res["url"]=df['imageUrlL'][0]
    res["author"]=df['bookAuthor'][0]
    res["year"]=df['yearOfPublication'][0]
    res["publisher"]=df['publisher'][0]
    #print(res)
        #i=books.imageUrlL[Top10.index[i]]
        #response = requests.get(i)
        #img = Image.open(BytesIO(response.content))
        #plt.figure()
        #plt.imshow(img)
    return res 
#searchandrate('044020450X')
def UserBasedCF(useridfor):
    idvalue=(random.choice(userids))
    print(idvalue)
    data=UserBasedCFCosine(4385, ratings_matrix)
    return data
def ItemBasedCF(useridfor):
    idvalue=(random.choice(userids))
    data=ItemBasedCFCosine(4385, ratings_matrix)
    return data
#UserBasedCF(1)

#print(getrandombooks())
#print(getuserid(int(input('enter id:'))))